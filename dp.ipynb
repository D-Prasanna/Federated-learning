{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2db7ced3-f3f2-42ab-82e3-a32a9b4da30f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opacus\n",
      "  Downloading opacus-1.5.3-py3-none-any.whl.metadata (8.4 kB)\n",
      "Requirement already satisfied: numpy<2.0,>=1.15 in c:\\users\\prasa\\anaconda3\\lib\\site-packages (from opacus) (1.26.4)\n",
      "Requirement already satisfied: torch>=2.0 in c:\\users\\prasa\\anaconda3\\lib\\site-packages (from opacus) (2.6.0)\n",
      "Requirement already satisfied: scipy>=1.2 in c:\\users\\prasa\\anaconda3\\lib\\site-packages (from opacus) (1.13.1)\n",
      "Requirement already satisfied: opt-einsum>=3.3.0 in c:\\users\\prasa\\anaconda3\\lib\\site-packages (from opacus) (3.4.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\prasa\\anaconda3\\lib\\site-packages (from torch>=2.0->opacus) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\prasa\\anaconda3\\lib\\site-packages (from torch>=2.0->opacus) (4.11.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\prasa\\anaconda3\\lib\\site-packages (from torch>=2.0->opacus) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\prasa\\anaconda3\\lib\\site-packages (from torch>=2.0->opacus) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\prasa\\anaconda3\\lib\\site-packages (from torch>=2.0->opacus) (2024.6.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\prasa\\anaconda3\\lib\\site-packages (from torch>=2.0->opacus) (75.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\prasa\\anaconda3\\lib\\site-packages (from torch>=2.0->opacus) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\prasa\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch>=2.0->opacus) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\prasa\\anaconda3\\lib\\site-packages (from jinja2->torch>=2.0->opacus) (2.1.3)\n",
      "Downloading opacus-1.5.3-py3-none-any.whl (251 kB)\n",
      "Installing collected packages: opacus\n",
      "Successfully installed opacus-1.5.3\n"
     ]
    }
   ],
   "source": [
    "!pip install opacus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da3f8fd8-9e92-4be7-b189-1529ddf55493",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from opacus import PrivacyEngine\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "636e68c6-b997-4b46-83f2-8cee311773b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d5ac264a-c67d-4140-aea0-497917dea2f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy without DP: 0.7528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prasa\\anaconda3\\Lib\\site-packages\\opacus\\privacy_engine.py:96: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "C:\\Users\\prasa\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1830: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with DP (noise_multiplier=1.0): 0.4944\n"
     ]
    }
   ],
   "source": [
    "# Load PIMA Indian Diabetes dataset (or use sklearn diabetes dataset)\n",
    "# Replace this with PIMA if using CSV; here, we use sklearn diabetes for demo\n",
    "from sklearn.datasets import load_diabetes\n",
    "data = load_diabetes()\n",
    "X = data.data\n",
    "y = (data.target > 140).astype(int)  # Convert to binary classification\n",
    "\n",
    "# Preprocessing\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64)\n",
    "\n",
    "# Simple feedforward model\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(X.shape[1], 16)\n",
    "        self.fc2 = nn.Linear(16, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        return self.fc2(x)\n",
    "\n",
    "def evaluate(model, dataloader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for x_batch, y_batch in dataloader:\n",
    "            x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "            outputs = model(x_batch)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += y_batch.size(0)\n",
    "            correct += (predicted == y_batch).sum().item()\n",
    "    return correct / total\n",
    "\n",
    "# Training function\n",
    "def train_model(model, train_loader, optimizer, criterion, epochs=5):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        for x_batch, y_batch in train_loader:\n",
    "            x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(x_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "# Baseline: Without Differential Privacy\n",
    "baseline_model = SimpleNN().to(device)\n",
    "optimizer = torch.optim.Adam(baseline_model.parameters(), lr=1e-3)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "train_model(baseline_model, train_loader, optimizer, criterion)\n",
    "acc_baseline = evaluate(baseline_model, test_loader)\n",
    "print(f\"Accuracy without DP: {acc_baseline:.4f}\")\n",
    "\n",
    "# With Differential Privacy\n",
    "dp_model = SimpleNN().to(device)\n",
    "optimizer_dp = torch.optim.Adam(dp_model.parameters(), lr=1e-3)\n",
    "privacy_engine = PrivacyEngine()\n",
    "\n",
    "dp_model, optimizer_dp, train_loader = privacy_engine.make_private(\n",
    "    module=dp_model,\n",
    "    optimizer=optimizer_dp,\n",
    "    data_loader=train_loader,\n",
    "    noise_multiplier=1.0,  # adjust based on epsilon desired\n",
    "    max_grad_norm=1.0,\n",
    ")\n",
    "\n",
    "train_model(dp_model, train_loader, optimizer_dp, criterion)\n",
    "acc_dp = evaluate(dp_model, test_loader)\n",
    "print(f\"Accuracy with DP (noise_multiplier=1.0): {acc_dp:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96bc7d0-f54b-449d-8c96-bddde116a054",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
